{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fe9ed8c",
   "metadata": {},
   "source": [
    "# About CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f245f4",
   "metadata": {},
   "source": [
    "* A **convolutional neural network (CNN)** is a type of **artificial neural network** designed for tasks such as image recognition and processing. It's particularly effective in analyzing visual data, thanks to its ability to automatically and adaptively learn spatial hierarchies of features from the input.\n",
    "\n",
    "\n",
    "\n",
    "* CNNs use a specialized architecture that includes **convolutional layers**, **pooling layers**, and **fully connected layers.** Convolutional layers apply convolution operations to the input data, capturing local patterns and features. Pooling layers then reduce the spatial dimensions of the representation, focusing on the most important information. Fully connected layers connect every neuron in one layer to every neuron in the next layer, enabling high-level reasoning.\n",
    "\n",
    "\n",
    "\n",
    "* CNNs have been highly successful in tasks like image classification, object detection, and facial recognition, among others. Their architecture is inspired by the visual processing in the human brain, making them well-suited for tasks involving spatial hierarchies of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893f64b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cc5c55",
   "metadata": {},
   "source": [
    "* The **Sequential()** represents a linear stack of layers to build a neural network model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff76fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315d0b17",
   "metadata": {},
   "source": [
    "# How the CNN works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb8801a",
   "metadata": {},
   "source": [
    "* The **convolutional layer** in a **Convolutional Neural Network (CNN)** performs the core operation of convolution. **Convolution** is a mathematical operation that combines two functions to produce a third function. In the context of CNNs, this operation is applied to the input data and a set of learnable filters or kernels.\n",
    "\n",
    "Here's a simplified explanation of what happens in a convolutional layer:\n",
    "\n",
    "**1. Filter (Kernel):** A small matrix that slides over the input data. Each element in the filter has a weight.\n",
    "\n",
    "**2. Convolution Operation:** The filter slides over the input data, and at each position, it performs element-wise multiplication with the local region of the input data. The results are summed up to produce a single value. This process is repeated across the entire input to produce an **output feature map.**\n",
    "\n",
    "**3. Learnable Weights:** The weights in the filter are learnable parameters that the neural network optimizes during training. These weights capture important patterns or features in the input data.\n",
    "\n",
    "**4. Activation Function:** After convolution, an **activation function (like ReLU - Rectified Linear Unit)** is often applied element-wise to introduce non-linearity and allow the network to learn complex relationships.\n",
    "\n",
    "* The convolutional layer's key advantage is its ability to automatically learn spatial hierarchies of features. It can capture local patterns in the input data, such as edges, textures, or shapes, and then combine them in deeper layers to recognize more complex patterns and objects.\n",
    "\n",
    "* In summary, the convolutional layer plays a crucial role in feature extraction and enables CNNs to effectively learn and recognize patterns in images or other grid-structured data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737d0c89",
   "metadata": {},
   "source": [
    "# Breakdown of parameters in Conv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0151a2",
   "metadata": {},
   "source": [
    "* **Conv2D** - 2D convolution used for processing 2D grid data like images.\n",
    "\n",
    "* **32** - Number of filters or kernels in the convolutional layer. Each filter detects different features in the input.\n",
    "\n",
    "* **(3*3)** - Filter size which is 3*3. During convolution this filter will slide over the input data in 3*3 patches.\n",
    "\n",
    "* **input_shape=(64,64,3)** - Specifies the shape of the input data. It's a 3D input with dimensions 64*64 and 3 channels.\n",
    "\n",
    "* **activation=relu** - Rectified Linear Unit activation function is applied element-wise to introduce non-linearity to the network. ReLU is commonly used in hidden layers to allow the network to learn complex patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523c873f",
   "metadata": {},
   "source": [
    "# Usage of filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6266f76d",
   "metadata": {},
   "source": [
    "* **Filters (or kernels)** in a convolutional layer play a crucial role in feature extraction. They act as small windows that slide over the input data, performing local operations to detect patterns and features. Here are a few reasons why filters are used in the convolution layer:\n",
    "\n",
    "**1. Feature Detection:** Filters are designed to detect specific features in the input data, such as edges, textures, or shapes. By sliding these filters over the entire input, the convolutional layer can capture local patterns.\n",
    "\n",
    "**2. Parameter Sharing:** Filters have learnable weights that are shared across the entire input. This parameter sharing reduces the number of parameters in the model, making it more efficient and reducing the risk of overfitting. The same filter is used at different spatial locations in the input.\n",
    "\n",
    "**3. Spatial Hierarchies:** Convolutional layers can learn hierarchical representations of features. Lower layers may capture simple features like edges, while deeper layers combine these simple features to recognize more complex patterns or objects. This hierarchical approach mimics how the visual system works in biological organisms.\n",
    "\n",
    "**4Translation Invariance:** The use of filters introduces translation invariance, meaning the network can recognize features regardless of their position in the input. If a particular pattern is detected in one part of the image, the same filter can detect a similar pattern elsewhere.\n",
    "\n",
    "**5. Local Connectivity:** Filters operate on local regions of the input, allowing the network to focus on local features and spatial relationships. This local connectivity is especially useful for grid-structured data like images.\n",
    "\n",
    "* In summary, filters in the convolutional layer enable the neural network to automatically learn and extract relevant features from the input data. This process is essential for the success of Convolutional Neural Networks (CNNs) in tasks such as image recognition, where understanding local patterns is crucial for identifying objects and patterns in images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a63f05",
   "metadata": {},
   "source": [
    "# About ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ce195f",
   "metadata": {},
   "source": [
    "* **ReLU, or Rectified Linear Unit**, is an **activation function** commonly used in neural networks, including Convolutional Neural Networks (CNNs). It introduces **non-linearity to the network by outputting the input directly if it is positive; otherwise, it outputs zero.**\n",
    "\n",
    "* Mathematically, the ReLU activation function is defined as:\n",
    "**f(x)=max(0,x)**\n",
    "\n",
    "* Here's a simple explanation of what it does:\n",
    "1. **Linear for Positive Values:** If the input x is positive, the function returns x itself. So, for any positive input, ReLU is a linear function.\n",
    "\n",
    "2. **Zero for Negative Values:** If the input x is negative, the function returns zero. This introduces non-linearity to the model, which is crucial for enabling the network to learn complex relationships and patterns.\n",
    "\n",
    "* The main advantages of using ReLU include:\n",
    "* **Simplicity:** ReLU is computationally efficient and easy to implement.\n",
    "\n",
    "* **Avoiding Vanishing Gradient Problem:** Unlike some other activation functions (e.g., sigmoid or tanh), ReLU does not saturate for positive inputs, helping to mitigate the vanishing gradient problem during training.\n",
    "\n",
    "* **Promoting Sparsity:** ReLU sets negative values to zero, which can lead to sparse representations. This sparsity can be beneficial for memory efficiency and generalization.\n",
    "\n",
    "* However, one drawback of ReLU is the \"dying ReLU\" problem, where neurons can sometimes become inactive (output zero) and stop learning if they consistently receive negative inputs during training. To address this, variants like Leaky ReLU and Parametric ReLU have been proposed, which allow a small, non-zero gradient for negative inputs, preventing neurons from becoming completely inactive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be51e358",
   "metadata": {},
   "source": [
    "# Why we have used Conv2D instead of Conv3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490cf821",
   "metadata": {},
   "source": [
    "* While the input to a convolutional layer is often described as a 3D image, it's more accurate to say it's a 3D tensor. \n",
    "\n",
    "* In the context of Convolutional Neural Networks (CNNs), the input data is indeed three-dimensional, representing an image with height, width, and color channels. The dimensions are typically organized as (height, width, channels). For example, a color image with dimensions 64x64 pixels and three color channels (RGB) would have an input shape of (64, 64, 3).\n",
    "\n",
    "* However, when we talk about passing this data through a 2D convolutional layer, we're referring to the fact that the convolution operation is applied in two spatial dimensions (height and width). **The third dimension (channels) is treated independently during the convolution process.**\n",
    "\n",
    "* In other words, each filter in the convolutional layer slides over the 2D spatial dimensions of the image, applying convolution independently to each color channel. The filters have depth that matches the number of input channels, and they slide across the height and width.\n",
    "\n",
    "* So, even though we refer to it as a 2D convolution layer, it's still able to handle the depth of the input data due to its design. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa8211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step1 - Convolution\n",
    "classifier.add(Conv2D(32, (3,3), input_shape = (64,64,3), activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcca210",
   "metadata": {},
   "source": [
    "# What is the Pooling layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c0e45b",
   "metadata": {},
   "source": [
    "* The **pooling layer** is a component commonly used in Convolutional Neural Networks (CNNs) to **downsample the spatial dimensions of the input data,** reducing its size and computational complexity. The pooling operation is applied independently to each depth slice of the input.\n",
    "\n",
    "* There are two main types of pooling layers: Max Pooling and Average Pooling.\n",
    "\n",
    "* **Max Pooling:** In max pooling, the output value of a specific region (often a 2x2 or 3x3 window) is the maximum value from that region in the input. It helps retain the most prominent features from the input, focusing on the presence of specific patterns.\n",
    "\n",
    "* **Average Pooling:** In average pooling, the output value for a specific region is the average of all values in that region in the input. It provides a smoothed version of the input and is less likely to emphasize specific features.\n",
    "\n",
    "* The pooling layer serves several purposes:\n",
    "* **Spatial Reduction:** It reduces the spatial dimensions (width and height) of the input, making subsequent layers computationally more efficient.\n",
    "\n",
    "* **Translation Invariance:** Pooling helps the network become somewhat invariant to small translations in the input, allowing it to recognize features regardless of their precise location.\n",
    "\n",
    "* **Feature Generalization:** By summarizing information from a local neighborhood, pooling encourages the network to focus on the most relevant and general features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f14291f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d695c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a second convolution layer\n",
    "classifier.add(Conv2D(32, (3,3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f6660e",
   "metadata": {},
   "source": [
    "# Flatten Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab2bb2f",
   "metadata": {},
   "source": [
    "* The **Flatten layer** is a type of layer in neural networks that is used to convert the input data, which could be a multi-dimensional tensor, into a one-dimensional vector. It essentially flattens the input without altering the actual data.\n",
    "\n",
    "* In the context of Convolutional Neural Networks (CNNs), the Flatten layer is often used after one or more convolutional and pooling layers when transitioning from spatial feature extraction to fully connected layers.\n",
    "\n",
    "* The **Flatten layer takes the output of the previous layer** (which is a multi-dimensional tensor resulting from the convolutional and pooling operations) and **flattens it into a one-dimensional vector.** This vector is then passed to one or more fully connected layers.\n",
    "\n",
    "* The Flatten layer is crucial when transitioning from convolutional and pooling layers to fully connected layers because **fully connected layers expect one-dimensional input.** The Flatten operation retains the learned spatial hierarchies in the data while preparing it for the final classification or regression layers of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16efc126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 - Add flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b80840b",
   "metadata": {},
   "source": [
    "# Dense Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a02de2",
   "metadata": {},
   "source": [
    "* **Dense layers**, also known as **fully connected layers**, are used in neural networks for their ability to learn complex patterns and representations from the input data. These layers connect every neuron from the previous layer to every neuron in the current layer, allowing for the learning of intricate relationships between features. \n",
    "\n",
    "**1. Capturing Non-linear Relationships:** Dense layers introduce non-linearity to the model, enabling it to learn and represent complex, non-linear relationships in the data. This is important for tasks where the input-output mapping is not a simple linear transformation.\n",
    "\n",
    "**2. Global Information Integration:** Dense layers integrate information from all neurons in the previous layer, providing a global view of the learned features. This is in contrast to convolutional and pooling layers, which focus on local patterns.\n",
    "\n",
    "**3. Feature Combination:** Dense layers can learn to combine features learned by earlier layers, creating more abstract and high-level representations of the input data. This ability is crucial for tasks like image recognition, natural language processing, and other complex pattern recognition tasks.\n",
    "\n",
    "**4. Task-Specific Representation:** The features learned by convolutional layers might be spatially invariant, but dense layers allow the network to create task-specific representations. For instance, in image classification, dense layers can learn to combine lower-level features to recognize higher-level patterns relevant to the specific classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edbd88d",
   "metadata": {},
   "source": [
    "# Sigmoid Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9083de8d",
   "metadata": {},
   "source": [
    "* The **sigmoid activation function**, also known as the **logistic function**, is a **common activation function** used in neural networks. It's particularly popular in the **output layer of binary classification models, where the goal is to produce a probability value between 0 and 1.**\n",
    "\n",
    "* The sigmoid function is defined as:\n",
    "**1/(1+e^-x)**\n",
    "\n",
    "* Here, **e** is the **base of the natural logarithm**, and **x is the input to the function.** The **output of the sigmoid function is always in the range (0, 1).**\n",
    "\n",
    "* Key properties of the sigmoid function:\n",
    "\n",
    "* **S-Shaped Curve:** The sigmoid function produces an S-shaped curve, mapping a wide range of input values to a smaller output range.\n",
    "\n",
    "* **Output Range:** The output is bounded between 0 and 1, making it suitable for representing probabilities.\n",
    "\n",
    "* **Smooth Gradient:** The sigmoid function has a smooth gradient, which is beneficial for optimization algorithms during the training of neural networks.\n",
    "\n",
    "* In the context of neural networks, the sigmoid activation function is often used in the output layer of binary classification models. It takes the output of the model and transforms it into a probability score, where values closer to **1 represent a higher probability of belonging to the positive class, and values closer to 0 represent a higher probability of belonging to the negative class.**\n",
    "\n",
    "* For other types of problems, such as multi-class classification or regression, different activation functions like softmax or tanh might be more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f705c1d8",
   "metadata": {},
   "source": [
    "# Why second Dense layer just has only 1 neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76e5c1b",
   "metadata": {},
   "source": [
    "* **First Dense Layer:** This layer has 128 neurons (or units) and uses the ReLU (Rectified Linear Unit) activation function. The choice of 128 neurons is somewhat arbitrary and depends on the specific architecture and requirements of your neural network. The ReLU activation introduces non-linearity to the model, allowing it to learn complex patterns.\n",
    "\n",
    "* **Second Dense Layer:** This layer has 1 neuron and uses the sigmoid activation function. The choice of 1 neuron with a sigmoid activation function in the output layer suggests that the network is designed for binary classification. The sigmoid activation function squashes the output to a range between 0 and 1, making it interpretable as a probability. In binary classification, a threshold can be applied (e.g., 0.5), where values above the threshold are predicted as one class, and values below are predicted as the other class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d35b6eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4 - Full connection\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19887c48",
   "metadata": {},
   "source": [
    "# Adam Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa27c54c",
   "metadata": {},
   "source": [
    "* **Adam**, short for **Adaptive Moment Estimation**, is an **optimization algorithm** commonly used for training neural networks. It is an extension of **stochastic gradient descent (SGD)** and incorporates concepts from both **momentum optimization** and **RMSprop (Root Mean Square Propagation).**\n",
    "\n",
    "* The key features of the Adam optimizer include:\n",
    "\n",
    "* **Adaptive Learning Rates:** Adam adapts the learning rates for each parameter individually. It uses the first-order momentum (like momentum optimization) and the second-order moment (like RMSprop) to adjust the learning rates.\n",
    "\n",
    "* **Momentum:** Similar to momentum optimization, Adam uses a momentum term to accelerate the optimization process by adding a fraction of the previous update to the current update.\n",
    "\n",
    "* **Root Mean Square Propagation (RMSprop):** Adam incorporates the concept of RMSprop by maintaining a moving average of the square of gradients. This helps in normalizing the learning rates, especially for parameters with high variance in their gradients.\n",
    "\n",
    "* **Bias Correction:** Adam performs bias correction during the initial iterations to counteract the fact that the momentum and squared gradient terms are initialized to zero, causing a bias towards zero at the beginning of training.\n",
    "\n",
    "\n",
    "* The Adam optimizer is known for its efficiency and effectiveness in a wide range of neural network architectures and tasks. It is particularly well-suited for **non-convex optimization** problems like training **deep neural networks.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ebb24d",
   "metadata": {},
   "source": [
    "# Binary Crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227dd334",
   "metadata": {},
   "source": [
    "* **Binary Crossentropy**, often referred to as **log loss**, is a **loss function** commonly used in **binary classification problems.** It measures the difference between the true labels and the predicted probabilities for a binary classification task. The binary crossentropy loss is defined mathematically as follows:\n",
    "\n",
    "**L(y,ŷ) = −(y⋅log(ŷ)+(1−y)⋅log(1−ŷ))**\n",
    "\n",
    "* Here:\n",
    "* **y** is the true label (either 0 or 1).\n",
    "* **ŷ** is the predicted probability of belonging to class 1 (the positive class).\n",
    "* **log** is the natural logarithm.\n",
    "\n",
    "* The binary crossentropy loss penalizes models more when they confidently predict the wrong class. If the true label is 1(y=1), the loss term −y.log(ŷ) is activated, penalizing the model more if the predicted probability (ŷ) is close to 0. If the true label is 0(y=0), the loss term −(1−ŷ)⋅log(1−ŷ)is activated, penalizing the model more if the predicted probability is close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb6184cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the CNN\n",
    "classifier.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9083c4c",
   "metadata": {},
   "source": [
    "# ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f806431",
   "metadata": {},
   "source": [
    "* **ImageDataGenerator** is a utility class provided by the Keras library for **real-time data augmentation during training.** Data augmentation involves applying various transformations to the training images to artificially increase the size of the training dataset and improve the generalization ability of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662944e1",
   "metadata": {},
   "source": [
    "* **rescale=1./255:** This scales the pixel values of the images by a factor of 1/255. This is a common practice to normalize the pixel values to the range [0, 1].\n",
    "\n",
    "* **shear_range=0.2:** **Shearing** is a **transformation** that shifts the position of pixels along a certain direction. The shear_range parameter determines the magnitude of the shear.\n",
    "\n",
    "* **zoom_range=0.2:** This parameter specifies the range for random zooming. A zoom_range of 0.2 means that the image can be zoomed in or out by a factor randomly chosen between [1 - 0.2, 1 + 0.2].\n",
    "\n",
    "* **horizontal_flip=True:** This enables random horizontal flipping of images. It provides additional variations by horizontally flipping some of the images during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e803802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the CNN to the images\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "409f5f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f545e9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('C:\\\\Users\\\\User\\\\Desktop\\\\Images\\\\training_set', \n",
    "                                                 target_size=(64,64),\n",
    "                                                 batch_size=32,\n",
    "                                                class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7e4984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
