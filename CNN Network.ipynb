{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6af1b18",
   "metadata": {},
   "source": [
    "# About CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0e67b7",
   "metadata": {},
   "source": [
    "* A **convolutional neural network (CNN)** is a type of **artificial neural network** designed for tasks such as image recognition and processing. It's particularly effective in analyzing visual data, thanks to its ability to automatically and adaptively learn spatial hierarchies of features from the input.\n",
    "\n",
    "\n",
    "\n",
    "* CNNs use a specialized architecture that includes **convolutional layers**, **pooling layers**, and **fully connected layers.** Convolutional layers apply convolution operations to the input data, capturing local patterns and features. Pooling layers then reduce the spatial dimensions of the representation, focusing on the most important information. Fully connected layers connect every neuron in one layer to every neuron in the next layer, enabling high-level reasoning.\n",
    "\n",
    "\n",
    "\n",
    "* CNNs have been highly successful in tasks like image classification, object detection, and facial recognition, among others. Their architecture is inspired by the visual processing in the human brain, making them well-suited for tasks involving spatial hierarchies of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a8a8ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73c01e5",
   "metadata": {},
   "source": [
    "* The **Sequential()** represents a linear stack of layers to build a neural network model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdbe5eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a26e270",
   "metadata": {},
   "source": [
    "# How the CNN works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9272c986",
   "metadata": {},
   "source": [
    "* The **convolutional layer** in a **Convolutional Neural Network (CNN)** performs the core operation of convolution. **Convolution** is a mathematical operation that combines two functions to produce a third function. In the context of CNNs, this operation is applied to the input data and a set of learnable filters or kernels.\n",
    "\n",
    "Here's a simplified explanation of what happens in a convolutional layer:\n",
    "\n",
    "**1. Filter (Kernel):** A small matrix that slides over the input data. Each element in the filter has a weight.\n",
    "\n",
    "**2. Convolution Operation:** The filter slides over the input data, and at each position, it performs element-wise multiplication with the local region of the input data. The results are summed up to produce a single value. This process is repeated across the entire input to produce an **output feature map.**\n",
    "\n",
    "**3. Learnable Weights:** The weights in the filter are learnable parameters that the neural network optimizes during training. These weights capture important patterns or features in the input data.\n",
    "\n",
    "**4. Activation Function:** After convolution, an **activation function (like ReLU - Rectified Linear Unit)** is often applied element-wise to introduce non-linearity and allow the network to learn complex relationships.\n",
    "\n",
    "* The convolutional layer's key advantage is its ability to automatically learn spatial hierarchies of features. It can capture local patterns in the input data, such as edges, textures, or shapes, and then combine them in deeper layers to recognize more complex patterns and objects.\n",
    "\n",
    "* In summary, the convolutional layer plays a crucial role in feature extraction and enables CNNs to effectively learn and recognize patterns in images or other grid-structured data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8ffd7e",
   "metadata": {},
   "source": [
    "# Breakdown of parameters in Conv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5984ecf9",
   "metadata": {},
   "source": [
    "* **Conv2D** - 2D convolution used for processing 2D grid data like images.\n",
    "\n",
    "* **32** - Number of filters or kernels in the convolutional layer. Each filter detects different features in the input.\n",
    "\n",
    "* **(3*3)** - Filter size which is 3*3. During convolution this filter will slide over the input data in 3*3 patches.\n",
    "\n",
    "* **input_shape=(64,64,3)** - Specifies the shape of the input data. It's a 3D input with dimensions 64*64 and 3 channels.\n",
    "\n",
    "* **activation=relu** - Rectified Linear Unit activation function is applied element-wise to introduce non-linearity to the network. ReLU is commonly used in hidden layers to allow the network to learn complex patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a55a40",
   "metadata": {},
   "source": [
    "# Usage of filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539e98c7",
   "metadata": {},
   "source": [
    "* **Filters (or kernels)** in a convolutional layer play a crucial role in feature extraction. They act as small windows that slide over the input data, performing local operations to detect patterns and features. Here are a few reasons why filters are used in the convolution layer:\n",
    "\n",
    "**1. Feature Detection:** Filters are designed to detect specific features in the input data, such as edges, textures, or shapes. By sliding these filters over the entire input, the convolutional layer can capture local patterns.\n",
    "\n",
    "**2. Parameter Sharing:** Filters have learnable weights that are shared across the entire input. This parameter sharing reduces the number of parameters in the model, making it more efficient and reducing the risk of overfitting. The same filter is used at different spatial locations in the input.\n",
    "\n",
    "**3. Spatial Hierarchies:** Convolutional layers can learn hierarchical representations of features. Lower layers may capture simple features like edges, while deeper layers combine these simple features to recognize more complex patterns or objects. This hierarchical approach mimics how the visual system works in biological organisms.\n",
    "\n",
    "**4Translation Invariance:** The use of filters introduces translation invariance, meaning the network can recognize features regardless of their position in the input. If a particular pattern is detected in one part of the image, the same filter can detect a similar pattern elsewhere.\n",
    "\n",
    "**5. Local Connectivity:** Filters operate on local regions of the input, allowing the network to focus on local features and spatial relationships. This local connectivity is especially useful for grid-structured data like images.\n",
    "\n",
    "* In summary, filters in the convolutional layer enable the neural network to automatically learn and extract relevant features from the input data. This process is essential for the success of Convolutional Neural Networks (CNNs) in tasks such as image recognition, where understanding local patterns is crucial for identifying objects and patterns in images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48ff908",
   "metadata": {},
   "source": [
    "# About ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefdbad9",
   "metadata": {},
   "source": [
    "* **ReLU, or Rectified Linear Unit**, is an **activation function** commonly used in neural networks, including Convolutional Neural Networks (CNNs). It introduces **non-linearity to the network by outputting the input directly if it is positive; otherwise, it outputs zero.**\n",
    "\n",
    "* Mathematically, the ReLU activation function is defined as:\n",
    "**f(x)=max(0,x)**\n",
    "\n",
    "* Here's a simple explanation of what it does:\n",
    "1. **Linear for Positive Values:** If the input x is positive, the function returns x itself. So, for any positive input, ReLU is a linear function.\n",
    "\n",
    "2. **Zero for Negative Values:** If the input x is negative, the function returns zero. This introduces non-linearity to the model, which is crucial for enabling the network to learn complex relationships and patterns.\n",
    "\n",
    "* The main advantages of using ReLU include:\n",
    "* **Simplicity:** ReLU is computationally efficient and easy to implement.\n",
    "\n",
    "* **Avoiding Vanishing Gradient Problem:** Unlike some other activation functions (e.g., sigmoid or tanh), ReLU does not saturate for positive inputs, helping to mitigate the vanishing gradient problem during training.\n",
    "\n",
    "* **Promoting Sparsity:** ReLU sets negative values to zero, which can lead to sparse representations. This sparsity can be beneficial for memory efficiency and generalization.\n",
    "\n",
    "* However, one drawback of ReLU is the \"dying ReLU\" problem, where neurons can sometimes become inactive (output zero) and stop learning if they consistently receive negative inputs during training. To address this, variants like Leaky ReLU and Parametric ReLU have been proposed, which allow a small, non-zero gradient for negative inputs, preventing neurons from becoming completely inactive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8273a4",
   "metadata": {},
   "source": [
    "# Why we have used Conv2D instead of Conv3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40091bf2",
   "metadata": {},
   "source": [
    "* While the input to a convolutional layer is often described as a 3D image, it's more accurate to say it's a 3D tensor. \n",
    "\n",
    "* In the context of Convolutional Neural Networks (CNNs), the input data is indeed three-dimensional, representing an image with height, width, and color channels. The dimensions are typically organized as (height, width, channels). For example, a color image with dimensions 64x64 pixels and three color channels (RGB) would have an input shape of (64, 64, 3).\n",
    "\n",
    "* However, when we talk about passing this data through a 2D convolutional layer, we're referring to the fact that the convolution operation is applied in two spatial dimensions (height and width). **The third dimension (channels) is treated independently during the convolution process.**\n",
    "\n",
    "* In other words, each filter in the convolutional layer slides over the 2D spatial dimensions of the image, applying convolution independently to each color channel. The filters have depth that matches the number of input channels, and they slide across the height and width.\n",
    "\n",
    "* So, even though we refer to it as a 2D convolution layer, it's still able to handle the depth of the input data due to its design. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66204c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step1 - Convolution\n",
    "classifier.add(Conv2D(32, (3,3), input_shape = (64,64,3), activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd329f9",
   "metadata": {},
   "source": [
    "# What is the Pooling layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d1af9",
   "metadata": {},
   "source": [
    "* The **pooling layer** is a component commonly used in Convolutional Neural Networks (CNNs) to **downsample the spatial dimensions of the input data,** reducing its size and computational complexity. The pooling operation is applied independently to each depth slice of the input.\n",
    "\n",
    "* There are two main types of pooling layers: Max Pooling and Average Pooling.\n",
    "\n",
    "* **Max Pooling:** In max pooling, the output value of a specific region (often a 2x2 or 3x3 window) is the maximum value from that region in the input. It helps retain the most prominent features from the input, focusing on the presence of specific patterns.\n",
    "\n",
    "* **Average Pooling:** In average pooling, the output value for a specific region is the average of all values in that region in the input. It provides a smoothed version of the input and is less likely to emphasize specific features.\n",
    "\n",
    "* The pooling layer serves several purposes:\n",
    "* **Spatial Reduction:** It reduces the spatial dimensions (width and height) of the input, making subsequent layers computationally more efficient.\n",
    "\n",
    "* **Translation Invariance:** Pooling helps the network become somewhat invariant to small translations in the input, allowing it to recognize features regardless of their precise location.\n",
    "\n",
    "* **Feature Generalization:** By summarizing information from a local neighborhood, pooling encourages the network to focus on the most relevant and general features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b644a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb499a8",
   "metadata": {},
   "source": [
    "########Describe the flatten layer#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c83c9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 - Add flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4203b855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
